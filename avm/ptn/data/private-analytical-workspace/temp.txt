Testy pro dnsZoneSaBlob,privateStorageAccount,storageAccountPrivateEndpoints, check doc

#- udelat max, default a waf a testy k nim
#- udelal jsem upgrade na nove verze - nejake nove params?
- Otestovat z vm + cross subs
#- Dokumentace + DJ
#- Testcases

https://www.databricks.com/blog/data-exfiltration-protection-with-azure-databricks
https://servian.dev/how-to-hardening-azure-databricks-using-terraform-feb23c231080
https://github.com/mddazure/azure-data-services-networking-part-2

============

VNEXT

- point2site with AAD auth
- ADLS
- blob storage
- ML
- SQL
- Postgre
-  VNEt + NSG Flow Logs

- Dalsi pattern na global ASEv3

============


V PS 7.4 (!!!!
cd "C:\_bicep-registry-modules\avm\ptn\data\private-analytical-workspace"
. C:\_bicep-registry-modules\avm\utilities\tools\Set-AVMModule.ps1
Set-AVMModule -ModuleFolderPath C:\_bicep-registry-modules\avm\ptn\data\private-analytical-workspace -Recurse


az login --use-device-code
cd C:\_TEMP\AVM.PAW\UC1
.\UC1.ps1

- Example KV purge
- ## Notes + media/doc/images folder

Alexander Sehr

DOTAZY
- advancedOptions a jak hlidat nevyplnene, conditional e.g. for subnetNamePrivateLink, front-end, back-end
- output a cfg strategije
- specify front-end, back-end
- jak pracovat (testy) s KV a Purge a softdelete | var kvDefaultCreateMode = 'recover'
- testing with existing resources cross grps
- jak dodat json v max test

$log | Format-List

Funguje pouze takto:
resource logExisting 'Microsoft.OperationalInsights/workspaces@2022-10-01' existing = if (!createNewLog) {
  name: createNewLog ? 'dummyName' : last(split(logAnalyticsWorkspaceResourceId!, '/'))
  scope: resourceGroup(
    createNewLog ? subscription().id : (split(logAnalyticsWorkspaceResourceId!, '/')[2]),
    createNewLog ? resourceGroup().id : (split(logAnalyticsWorkspaceResourceId!, '/')[4])
  )
}


- jak priradit skupiny do repository
- Zacal jsem dostavat spoustu emailu. E.g. [Azure/azure-powershell]
Mate Barabas, ze kris dela super job - chtel bych mit pristup do telemetry a vlastne vsichni vlastnici modulu by meli videt jak moc ktery modul dela ACR a jak se pouziva - to zvedne motivaci, protoze to mzueme ukazat nasim mgr, ze to co delame ma impact


https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/conditional-resource-deployment#new-or-existing-resource

https://blog.ivemo.se/Using-loops-with-Bicep/


Recover (Na KV) udela skutecne obnovu ke stavu vymazani, ignoruje aktualni nastaveni v bicep. Pro aktualni aplikaci je potreba pustit znova a bez recover ale s default



Databricks
Go to: https://accounts.azuredatabricks.net/
Catalogs
Click Catalog
Click three dots top right corner, delete


unity storage credentials
https://learn.microsoft.com/en-us/azure/databricks/connect/unity-catalog/manage-storage-credentials




/*

Names
https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-abbreviations
vnet
log
dbw
kv

TODO
- Private Links
- Solution Owner
- jak pocitat publicNetworkAccess
- outputs + conditional outputs
- lepsi networkAclsType

- Conditional pokud not empty logAnalyticsWorkspaceResourceId nebo pak user defined struct s LAW params
  - dailyQuotaGb
  - dataRetention

- Conditional pokud not empty keyVaultResourceId nebo pak user defined struct s KV params
  - createMode
  - enablePurgeProtection
  - enableSoftDelete
  - softDeleteRetentionInDays
  - sku

- Required / Conditional Required if (…) / Optional / Generated

ID: BCPNFR16 - Category: Testing - Post-deployment tests
https://azure.github.io/Azure-Verified-Modules/specs/bicep/#id-bcpnfr16---category-testing---post-deployment-tests

ID: BCPNFR4 - Category: Documentation - Parameter Input Examples
https://azure.github.io/Azure-Verified-Modules/specs/bicep/#id-bcpnfr4---category-documentation---parameter-input-examples

The defaults folder contains a test instance that deploys the module with the minimum set of required parameters.
This includes input parameters of type Required plus input parameters of type Conditional marked as required for WAF compliance.

The waf-aligned folder contains a test instance that deploys the module in alignment with the best-practices of the Azure Well-Architected Framework.
This includes input parameters of type Required, parameters of type Conditional marked as required for WAF compliance, and parameters of type Optional useful for WAF compliance.

The max folder contains a test instance that deploys the module using a large parameter set, enabling most of the modules’ features.

*/


environment().suffixes

https://azure.github.io/Azure-Verified-Modules/specs/shared/#id-rmfr4---category-composition---avm-consistent-feature--extension-resources-value-add
Optional Features/Extension Resources	Bicep Parameter Name	Terraform Variable Name	MUST/SHOULD
Diagnostic Settings	diagnosticSettings	diagnostic_settings	MUST
Role Assignments	roleAssignments	role_assignments	MUST
Resource Locks	lock	lock	MUST
Tags	tags	tags	MUST
Managed Identities (System / User Assigned)	managedIdentities	managed_identities	MUST
Private Endpoints	privateEndpoints	private_endpoints	MUST
Customer Managed Keys	customerManagedKey	customer_managed_key	MUST
Azure Monitor Alerts	alerts	alerts	SHOULD



az keyvault list-deleted
az keyvault purge --name jbipaw-kv
az keyvault recover --name jbipaw-kv --location "North Europe"
Undo-AzKeyVaultRemoval -VaultName jbipaw-kv -ResourceGroupName AVM.PAW -Location "North Europe"
Remove-AzKeyVault -VaultName jbipaw-kv -InRemovedState -Force -Location 'North Europe'


$log = Get-AzOperationalInsightsWorkspace -ResourceGroupName avm.paw -Name jbipaw-log
$log.WorkspaceFeatures.DailyQuotaGb







All resources of the solution can be tagged, locked.
Owner role can be assigned via "solutionAdministrators" parameter.

All resources has name based on the input parameter name.
All resources are collecting diagnostic and monitoring information and storing the data into newly created or predefined Log Analytcial Workspace.
Solution can have optionally enabled additional analytical services as a part of the solution (for example parameter "enableDatabricks").
More advanced options for the solution can be finetuned through the parameter "advancedOptions".

Some Azure services of the solution can be accessed over public endpoint (when desired)
and further restricted through network access control list where public IP of accessing client can be allowed.





Solution always require Virtual network.
At minimum it requires one subnet for accomodating private link endpoints.
As more optional services are enabled it adds more requirements
on network, subnets, subnet sizes, network security groups, NSG access control list
private endpoint, DNS zones, etc.
For example if Azure Databricks service is enabled it
will create virtual network and all required components according to the best practicies.
If Enterpirse virtual network will be provided by network or cloud team it needs to meet
enabled services expectations.
All Network Security Groups, Network Security Group Rules, DNS Zones and DNS forwarding, private endpoints,
domain zones for Key Vault, Azure Databricks and subnet delegations must be properly configured.
For example see following documentation: https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/vnet-inject#--virtual-network-requirements.

This is Relatively easy, fast and still secure deployment.
Suitable for quick solutions which needs analytical workspace to build quickly.
Solution will create all needed components like VNET, Monitoring, Key Vault, permissions and analytical services.
All with best practicies applied.
Because of the isolated network, consumers public IP addresses needs to be specified
as allowed to access the environment over secured public endpoints.
Solution will be accessible only from specified public IP addresses.
Identity of the solution administrator or group needs to be provided to access and manage the solution.
There is no need to precreate virtual network or any other components.





-	Monitoring
o	New dedicated LAW will be created for the solution
o	LAW parameter id must be empty
o	Advanced options can be specified


-	KV
o	New dedicated KV will be created for the solution
o	KV parameter id must be empty
o	Advanced options can be specified
o	Public Access allowed when IP address specified
o	PL is created with DNS zone

To provide administrators permissions for the newly created services in the solution use the parameter ```solutionAdministrators.*```. Use or Entra ID Groups can be specified. Those identities will become owners of the solution and can further delegate permissions. Those identities will also receive 'Key Vault Administrator' privileges specifically for Azure Key Vaults that are newly created.</br>
You should always specify some identity which will be the Solution Administrator to use solution meaningfully.


-	Solution Admins
o	solutionAdministrators should be provided to specific user or group
	They will be owners/administrators of all resources create for the solution including secrets management in KV

-	ADB
o	All is prepared
o	Command to further protect ADB
o	2x Private links + Zone
o	Public access can be enabled when client public IP address is specified




This use case is trying to adjust to enterprise infrastructure expectations.
Some companies for example doesn't allow public IP addresses at all in the solutions.

The solution will still create some components like Monitoring, Key Vault, permissions, and analytical services. But some pre and post configuration might be needed.

This is needs to be in balance - complexity of the deployment and enterprise security expectations.

This option give you choice to customize the infrastructure to your needs but it often means requesting some customized services from the cloud, security and network team which kills the agility and introduces project delays.

The trade off of this use case is longer deployment cycle vs being aligned to enterprise policies and infrastructure expectations.

Complexity might be especially on Virtual Network side.

Expect peering requirement (hub and spoke model), dns configurations, private zones requirements, private links, private links DNS forwarding, virtual network delegations, etc. Also different analytical services migh have different virtual network expectations.


No explicit public IPs are required in this use case. All services can benefit from private access only.

The identity of the solution administrator or the managing group must be submitted to gain access and control over the solution.




Enterprise network team must pre-create virtual network for you with other required network components and configurations.
It should be spoke type network peered into hub virtual network in the hub and spoke model.



Customer / Network team is responsible for
creation of dedicated virtual network with not colliding enterprise address space for the solution with appropriate subnets with appropriate subnet sizes. Some subnets require delegations, configuring enterprise DNS on Virtual Network level, register private links into dedicated enterprise ready private link private DNS zones with forwarding for private link resolutions, dedicated Network Security Groups with specific rules for given services, etc.

At minimum subnet /26 for hosting private links must be created. Typically more subnets with different sizes are needed as more analytical services are enabled.
Services in the solution have different needs. For example see Azure Databricks requirements:
- https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/vnet-inject#network-security-group-rules-for-workspaces
- https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/udr

Note required subnets, subnets sizing, routing, DNS configurations, Network security groups, delegations for 'Microsoft.Databricks/workspaces', private endpoints.



For leveraging pre defined virtual network from Enterprise Network team (this use case), the Virtual Network ```virtualNetworkResourceId``` parameter must point to the existing Virtual Network.



From this perspective it is the same like use cas 1.
The difference from the use case 1 is that customer typically need full private access only and for that customer
is responsible for configuring private endpoints for created Azure Key vault,
registering DNS record pointing to private IP address under private endpoint NIC.
Customer is also responsible for creating or using existing Azure Key Vault private DNS zone to support private endpoint resolution
and integrate this with enterprise DNS and DNS forwarding mechanism.


If private and public access is desired, the ```advancedOptions.networkAcls.ipRules``` parameter can be configured,
with the client's public IP in the allowed range.



- When Azure Databricks is enabled, the public IP must be enabled manually.
- https://learn.microsoft.com/en-us/azure/databricks/security/network/front-end/ip-access-list#ip-access-lists-overview
- https://accounts.azuredatabricks.net/login | https://learn.microsoft.com/en-us/azure/databricks/security/network/front-end/ip-access-list-account#enable-ip-access-lists
- https://learn.microsoft.com/en-us/azure/databricks/security/network/front-end/ip-access-list-workspace
- https://learn.microsoft.com/en-us/azure/databricks/compute/web-terminal |


This use case is typically about integrating with own virtual network. See: [Virtual Network for Use Case 2](#vnet-uc2).
Virtual Network needs to be prepared by network team to host private links subnet and two additional subnets with delegations for Azure Databricks.
Next, two private endpoints, network security groups and a Azure Databricks Zone needs to be created.</br>










- Customer needs to provide Spoke Virtual Network dedicated to the workload with subnets for the solution.
  - Spoke Network needs to be peered with Hub Network - typically with central Firewall and connectivity to enterprise network.
  - Private Link Subnet, front-end and backend-end subnet for Azure Databricks
  - !!! Subnets for Azure Databricks must have delegations for 'Microsoft.Databricks/workspaces' enabled
  - Each subnet for Azure Databricks must have same NSG associated
  - NSG for ADb must have following rules - https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/vnet-inject#network-security-group-rules-for-workspaces
  - ADB PEPs
  - Delegation, RT, NSG, subnets, VNET with large size, DNS, Peerings, PL DNS
  - ADB UDR?? https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/udr
  - solutionAdministrators are owners for all resources, KV administrator


This use case is trying to integrate and adjust to specific needs of enterprise infrastructure.
It is very similar and extends use case xxxxxx but goes even further.
Not only this use case integrates with pre-provisioned virtual network to keep all the traffic private but it will also integrate with
pre-provisioned Azure Key Vault and central Azure Log Analytics workspace.
This means that cloud team and network team will can provide core central components
for the solution and this pattern will link the components together.
Cloud and network team are still responsible to configure all prerequisities like in the use case xxx
and also provide private endpoint, zones, DNS resolution, permissions/access for different users, etc. for Azure Key Vault and central Azure Log Analytics workspace if needed.

